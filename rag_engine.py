"""
rag_engine.py
ูุญุฑู RAG ูุญุณูู ููุฅุฌุงุจุฉ ุงูุฏูููุฉ ูุงูุงุญุชุฑุงููุฉ ุนูู ุฃุณุฆูุฉ ุงูุนููุงุก
ุญูู ุดุฑูุฉ ุงูุดูุณ ุชูููููู.
"""

import logging
from typing import List, Optional
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document

# ุฅุนุฏุงุฏ ุงูุณุฌูุงุช
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === ุชููุฆุฉ ุงููุธุงู ===
try:
    logger.info("ุฌุงุฑู ุชุญููู ูููุฐุฌ ุงูุชุถููู...")
    embeddings = HuggingFaceEmbeddings(
        model_name="all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True}
    )
    
    logger.info("ุฌุงุฑู ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌูุฉ...")
    vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
    
    # Retriever ุฐูู: ูุฌูุน ุจูู k ุนุงูู ูุนุชุจุฉ ุชุดุงุจู
    retriever = vectorstore.as_retriever(
        search_type="similarity_score_threshold",
        search_kwargs={"k": 8, "score_threshold": 0.25}
    )
    
    logger.info("ุฌุงุฑู ุชููุฆุฉ ุงููููุฐุฌ ุงููุบูู...")
    llm = ChatOllama(model="llama3", temperature=0.05, num_ctx=3072)  # ุฃูู ุญุฑุงุฑุฉ = ุฃูุซุฑ ุฏูุฉ
    
    logger.info("โ ุชู ุชููุฆุฉ ุงููุธุงู ุจูุฌุงุญ")
    
except Exception as e:
    logger.error(f"โ ุฎุทุฃ ูู ุชููุฆุฉ ุงููุธุงู: {str(e)}")
    raise

# ูุงูุจ ุชุนูููุงุช ูุฑููุฒ ุนูู ุงูุงุณุชุฎูุงุต ุงูุฏููู
prompt = ChatPromptTemplate.from_messages([
    ("system", """ุฃูุช ูุณุงุนุฏ ุฐูู ูุดุฑูุฉ "ุงูุดูุณ ุชูููููู". ูููุชู:
1. **ุงุณุชุฎูุงุต ุงููุนูููุงุช ูุจุงุดุฑุฉ** ูู ุงูุณูุงู ุฃุฏูุงู โ ูุง ุชุฎุชูู.
2. **ูุธู ุงูุฅุฌุงุจุฉ** ุจุงุณุชุฎุฏุงู ุนูุงููู ูุฑุนูุฉ ุฃู ููุงุท ุญุณุจ ุงูุญุงุฌุฉ.
3. ุฅุฐุง ุทููุจ "ุงูุจุงูุงุช" ุฃู "ุงูุฃุณุนุงุฑ"ุ **ุงุฐูุฑ ุฌููุน ุงูุจุงูุงุช ุงููุชููุฑุฉ** ูุน:
   - ุงุณู ุงูุจุงูุฉ
   - ุงูุณุนุฑ (ุจุงูุฏููุงุฑ ุงูุนุฑุงูู)
   - ููุน ุงูุจุงูุฉ (ูุงูุจุฑ/ูุงูุฑูุณ/ููุตุฉ)
   - ูุตู ููุฌุฒ
4. ุฅุฐุง ูู ุชุฌุฏ ูุนูููุงุชุ ูู: "ุนุฐุฑูุงุ ูุง ุชูุฌุฏ ูุนูููุงุช ูุงููุฉ ุญูู ูุฐุง ุงูููุถูุน ูู ูุงุนุฏุฉ ุจูุงูุงุชูุง ุงูุญุงููุฉ."
5. ูู ููุฌุฒูุงุ ุงุญุชุฑุงูููุงุ ููุฏููุง.
6. ูุง ุชูุฑุฑ ููุณ ุงููุนูููุฉ ุฃูุซุฑ ูู ูุฑุฉ.
"""),
    ("human", """**ุงูุณูุงู (ุงุณุชุฎูุต ููู ููุท):**
{context}

**ุณุคุงู ุงูุนููู:**
{input}

**ุงูุฅุฌุงุจุฉ (ุงุณุชูุงุฏูุง ุญุตุฑููุง ุฅูู ุงูุณูุงู ุฃุนูุงู):**""")
])


def filter_and_deduplicate_docs(docs: List[Document]) -> str:
    """
    ุชุตููุฉ ุงููุณุชูุฏุงุช ุบูุฑ ุงููููุฏุฉ + ุฅุฒุงูุฉ ุงูุชูุฑุงุฑ + ุงูุญุฏ ูู ุงูุทูู
    """
    if not docs:
        return "ูุง ุชูุฌุฏ ูุนูููุงุช ูุงููุฉ."
    
    # ุงุณุชุจุนุงุฏ ุฃูุณุงู ุงูุฃุฎุจุงุฑ ุงูุทูููุฉ (ุบูุฑ ูุจุงุดุฑุฉ ููุงุณุชุนูุงู)
    filtered = []
    for doc in docs:
        content = doc.page_content
        # ุงุณุชุจุนุงุฏ ุฅุฐุง ูุงู ูุญุชูู ุนูู ูููุงุช ูุซู "ุดุงุฑููุง ูู ูุนุงููุฉ" ุฃู "ูุฑุดุฉ ุนูู"
        if any(term in content for term in ["ุดุงุฑููุง ูู ูุนุงููุฉ", "ูุฑุดุฉ ุนูู", "ุฑุนุงุฉ", "ุญุฏุซ", "ูุคุชูุฑ"]):
            if len(content) > 300:
                # ูุจูู ููุท ุฌููุฉ ููุฌุฒุฉ ุฅู ููุฌุฏุช
                first_line = content.split("\n")[0]
                if "ุดูุณ" in first_line or "ุจุงูุฉ" in first_line or "ุณุนุฑ" in first_line:
                    filtered.append(first_line)
                continue
        filtered.append(content)
    
    # ุฅุฒุงูุฉ ุงูุชูุฑุงุฑ ุชูุฑูุจููุง
    unique_contents = []
    seen = set()
    for text in filtered:
        key = text[:50].strip().lower()
        if key not in seen:
            seen.add(key)
            unique_contents.append(text)
    
    # ุฏูุฌ ุงููุต ูุน ุญุฏ ุฃูุตู ~1500 ุญุฑู (ูุชุญุณูู ุงูุณุฑุนุฉ ูุชุฌูุจ overflow)
    context = "\n---\n".join(unique_contents)
    return context[:1500]


# ุณูุณูุฉ RAG ูุญุณููุฉ
rag_chain = (
    {"context": retriever | filter_and_deduplicate_docs, "input": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)


def expand_query(question: str) -> str:
    """ุชูุณูุน ุฐูู ููุณุคุงู ุจูุงุกู ุนูู ุฃููุงุท ุดูุณ ุชูููููู"""
    q = question.strip().lower()
    original = question.strip()
    
    # ุฃููุงุท ุงูุจุญุซ ุงูุดุงุฆุนุฉ
    if any(w in q for w in ["ุงูุณุนุฑ", "ุณุนุฑ", "ูู", "ุฏููุงุฑ"]):
        return f"{original} ุจุงูุงุช ุงูุฅูุชุฑูุช ุงูุฃุณุนุงุฑ FTTH WiFi ุฏููุงุฑ ุนุฑุงูู"
    
    if any(w in q for w in ["ุจุงูุฉ", "ุงุดุชุฑุงู", "ุงูุจุงูุงุช", "ุจุงูุงุช"]):
        return f"{original} ุจุงูุงุช ุงูุฅูุชุฑูุช FTTH WiFi ุงูููุตุฉ ูุงูุจุฑ Star Sun Neptune Galaxy Star"
    
    if "ุชุบุทูุฉ" in q or "ููุทูุฉ" in q or "ุฃูู" in q:
        return f"{original} ุชุบุทูุฉ ุจุบุฏุงุฏ ุฏูุงูู ุจุงุจู ุงููุญุงูุธุงุช"
    
    if "ุฏุนู" in q or "ูุณุงุนุฏู" in q or "24" in q:
        return f"{original} ุฏุนู ููู 24/7 ุฎุฏูุฉ ุงูุนููุงุก"
    
    return original


def get_answer(question: str) -> str:
    """
    ุงูุญุตูู ุนูู ุฅุฌุงุจุฉ ุฏูููุฉ ูุณุฑูุนุฉ
    """
    if not question or not question.strip():
        return "ูุฑุญุจุงู! ๐ ููู ูููููู ูุณุงุนุฏุชู ุงููููุ ุงุณุฃููู ุนู ุจุงูุงุช ุงูุฅูุชุฑูุชุ ุงูุฃุณุนุงุฑุ ุงูุชุบุทูุฉุ ุฃู ุฃู ูุนูููุงุช ุนู ุดูุณ ุชูููููู."

    clean_q = question.strip()
    logger.info(f"ูุนุงูุฌุฉ ุงูุณุคุงู: '{clean_q}'")

    # ุชูุณูุน ุงูุงุณุชุนูุงู
    expanded = expand_query(clean_q)
    if expanded != clean_q:
        logger.debug(f"ุงูุณุคุงู ุงูููุณูุน: {expanded}")

    try:
        # ุงุณุชุฑุฌุงุน ุฃููู
        docs = retriever.invoke(expanded)
        logger.info(f"ุชู ุงุณุชุฑุฌุงุน {len(docs)} ูุณุชูุฏ(ุงุช)")

        # ุฅุฐุง ูุดู ุงูุงุณุชุฑุฌุงุนุ ูุญุงูู ุจุฎุทูุงุช ุงุญุชูุงุทูุฉ
        if not docs:
            fallback_queries = [
                clean_q,
                " ".join([w for w in clean_q.split() if len(w) > 2]),
                "ุจุงูุงุช ุฃุณุนุงุฑ ุฏุนู ุชูุงุตู"
            ]
            for fq in fallback_queries:
                docs = retriever.invoke(fq)
                if docs:
                    logger.info(f"ุชู ุงูุงุณุชุฑุฌุงุน ุจุงุณุชุฎุฏุงู ุงูุงุณุชุนูุงู ุงูุงุญุชูุงุทู: {fq}")
                    break

        # ุชูููุฐ ุงูุณูุณูุฉ
        response = rag_chain.invoke(clean_q)
        
        # ุชูุธูู ุงูุฅุฌุงุจุฉ
        response = response.strip()
        if not response or "ูุง ุฃููู" in response or "ุบูุฑ ูุชููุฑ" in response:
            response = "ุนุฐุฑูุงุ ูุง ุชูุฌุฏ ูุนูููุงุช ูุงููุฉ ุญูู ูุฐุง ุงูููุถูุน ูู ูุงุนุฏุฉ ุจูุงูุงุชูุง ุงูุญุงููุฉ.\n\nูู ุชุฑูุฏ ูุนุฑูุฉ ูุนูููุงุช ุนู ุจุงูุงุชูุง ุฃู ุฎุฏูุงุชูุงุ ๐"
        
        return response

    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุณุคุงู: {e}")
        return "ุนุฐุฑูุงุ ุญุฏุซ ุฎุทุฃ ุชููู. ูุฑุฌู ุงููุญุงููุฉ ูุงุญููุง ุฃู ุงูุงุชุตุงู ุจูุง ุนูู 6449."